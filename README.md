# MLOps Platform

비전 AI 모델 개발을 위한 엔드투엔드 MLOps 플랫폼 프로젝트입니다.

## 📋 프로젝트 개요

본 프로젝트는 ML 엔지니어가 격리된 개발 환경에서 모델을 개발하고, 라벨링된 데이터로 지속적으로 모델을 개선하며, 안전하게 배포할 수 있는 MLOps 플랫폼을 설계하고 구현하는 것을 목표로 합니다.

### 문제 상황

- 각 엔지니어가 로컬 환경에서 개발하여 환경 불일치와 재현성 문제 발생
- 학습된 모델을 수동으로 공유하는 방식으로 인한 비효율성
- 새로운 데이터 생성 시 모델 학습 반영 과정이 수동적
- 모델 배포 시 성능 검증 없이 교체하여 데이터 품질 저하 발생

### 해결 목표

- 격리된 GPU 개발 환경 제공
- 자동화된 모델 학습 파이프라인 구축
- 안전한 모델 배포 프로세스 구현
- 분산 학습 지원

## 🎯 주요 기능

### 1. 모델 개발 환경

- **격리된 GPU 개발 환경 할당**
  - ML 엔지니어가 GPU 자원(종류, 수량)을 요청하면 격리된 개발 환경 할당
  - 엔지니어의 IDE에서 원격으로 해당 환경에 접속하여 개발
  - 컨테이너 기반으로 제공되며, 엔지니어별로 독립적인 환경 보장

### 2. 모델 학습 파이프라인

- **실험 추적 및 버전 관리**
  - 학습된 모델의 메트릭, 하이퍼파라미터, 아티팩트 추적 및 버전 관리
  - 모델은 단계별(실험 → 검증 → 운영)로 관리
  - 검증을 통과한 모델만 운영 환경에 배포

- **자동 재학습**
  - 새로운 라벨링 데이터가 일정 수준 누적되면 자동으로 모델 재학습 트리거
  - 재학습 시 기존 모델의 지식을 유지하면서 새로운 데이터를 학습 (전이학습)

### 3. 모델 서빙

- **다양한 서빙 형태 지원**
  - **Batch 서빙**: 라벨링 데이터의 전처리 과정에서 전체 데이터에 대한 Pseudo labeling 수행
  - **One-by-One 서빙**: 라벨링 도구에서 서빙 API를 호출하여 예측 결과를 미리 채우고, 라벨러가 검수/수정

- **안전한 배포**
  - 새 모델 배포 시 일부 트래픽만 새 모델로 전환하여 성능 검증 (Canary 배포)
  - 문제가 없으면 전체 트래픽을 전환

### 4. 분산 학습

- **분산 학습 지원**
  - ML 엔지니어가 작성한 단일 GPU 학습 코드를 최소한의 수정으로 분산 학습 환경에서 실행 가능
  - 분산 학습 작업의 스케줄링 및 모니터링 지원

## 📐 설계 산출물

### 필수 산출물

1. **System Architecture Diagram**
   - 전체 시스템 구성요소와 데이터 흐름
   - 각 구성요소의 역할과 선택 이유

2. **Sequence Diagram**
   - ML 엔지니어의 모델 개발 및 학습 흐름
   - 새로운 데이터 누적 → 재학습 → 배포까지의 흐름

### 옵션 산출물

1. **기술 스택 비교 분석**
2. **예상 이슈 및 해결 방안**

## 🛠 기술 스택 (예정)

- **컨테이너 오케스트레이션**: Kubernetes
- **MLOps 플랫폼**: MLflow, Kubeflow (검토 중)
- **모델 서빙**: TensorFlow Serving, TorchServe, KServe (검토 중)
- **분산 학습**: PyTorch DDP, Horovod (검토 중)
- **모니터링**: Prometheus, Grafana
- **CI/CD**: GitHub Actions, ArgoCD

## 📁 프로젝트 구조

```
mlops-platform/
├── README.md
├── docs/
│   ├── architecture/
│   │   └── system-architecture.md
│   ├── sequence/
│   │   └── model-lifecycle.md
│   └── design-decisions.md
├── infrastructure/
│   ├── kubernetes/
│   └── terraform/
└── examples/
    └── sample-training-code/
```

## 🚀 시작하기

### 사전 요구사항

- Kubernetes 클러스터 (로컬: minikube, kind 등)
- Docker
- kubectl

### 설치 방법

```bash
# 저장소 클론
git clone <repository-url>
cd mlops-platform

# Kubernetes 리소스 배포
kubectl apply -f infrastructure/kubernetes/
```

## 📝 개발 로드맵

- [ ] 시스템 아키텍처 설계
- [ ] 시퀀스 다이어그램 작성
- [ ] 개발 환경 구성 (Kubernetes, 컨테이너 이미지)
- [ ] 모델 학습 파이프라인 구현
- [ ] 모델 서빙 인프라 구축
- [ ] 분산 학습 지원 구현
- [ ] 모니터링 및 로깅 시스템 구축

## 🤝 기여하기

이 프로젝트는 학습 및 포트폴리오 목적으로 진행되는 토이 프로젝트입니다.

## 📄 라이선스

MIT License
